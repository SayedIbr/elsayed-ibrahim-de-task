# elsayed-ibrahim-de-task
# NYT Books Data Pipeline

## Overview

This project implements an ELT (Extract, Load, Transform) pipeline using Apache Airflow and PostgreSQL. The pipeline extracts data from the New York Times Books API, loads it into a PostgreSQL data warehouse, and transforms it into a dimensional model using a star schema. The project is containerized using Docker, making it easy to deploy and manage.

## Technology Stack

- **Apache Airflow**: Orchestrates the data pipeline.
- **PostgreSQL**: Serves as the data warehouse.
- **Docker**: Containerizes the application for easy deployment.
- **Python**: Used for scripting and custom operators in Airflow.
- **Pandas**: Used for data manipulation and export to CSV.

## Project Structure

├── docker-compose.yml
├── dags
│ └── nyt_books_data_pipeline.py
├── plugins
│ ├── sql_analytical_queries
│ │ ├── book_top_3_longest_2022.sql
│ │ ├── lists_least_unique_books.sql
│ │ ├── top_publishers_quarterly_rank.sql
│ │ └── book_purchases_by_team_2023.sql
│ ├── ddls
│ │ ├── create_staging_tables.sql
│ │ ├── create_ods_tables.sql
│ │ ├── create_dim_and_fact_tables.sql
│ │ ├── upsert_to_ods.sql
│ │ ├── truncate_staging_tables.sql
│ │ ├── populate_dim_tables.sql
│ │ └── populate_fct_tables.sql
├── config
├── logs
└── plugins



## Setting Up the Environment

### Prerequisites

- Docker and Docker Compose installed on your machine.
- New York Times API Key.

### Configuration

1. **Docker Compose File**: `docker-compose.yml` is configured to set up Airflow and PostgreSQL.

2. **Folders**:
   - `dags`: Contains the DAG (Directed Acyclic Graph) for Airflow.
   - `plugins`: Contains SQL queries and additional plugins for Airflow.
     - `sql_analytical_queries`: Holds analytical SQL queries.
     - `ddls`: Holds DDL (Data Definition Language) SQL scripts for creating and managing database tables.
   - `config`: Holds CSV output files.
   - `logs`: Holds logs generated by Airflow.

### Instructions to run the solution
**Initialize Airflow**:

docker-compose up airflow-init

**Start the Application**:

docker-compose up


### Detailed Steps in the DAG
**Create Staging and ODS Tables**:

create_staging_tables_task: Creates staging tables.
create_ods_tables_task: Creates ODS (Operational Data Store) tables.

**Fetch and Store Data**:

Tasks (fetch_and_store_data_2021, fetch_and_store_data_2022, fetch_and_store_data_2023) to fetch data from the NYT API and store it in staging tables.

**Upsert to ODS**:

upsert_to_ods_task: Upserts data from staging to ODS.

**Truncate Staging Tables**:

truncate_staging_tables_task: Truncates staging tables after data is upserted to ODS.

**Populate Dimension and Fact Tables**:

populate_dim_tables_task: Loads data into dimension tables in parallel.
populate_fact_table_task: Loads data into fact table after dimension tables are populated.

**Execute Analytical Queries and Export to CSV**:

execute_query_1: Executes and exports the result of book_top_3_longest_2022.sql to CSV.
execute_query_2: Executes and exports the result of lists_least_unique_books.sql to CSV.
execute_query_3: Executes and exports the result of top_publishers_quarterly_rank.sql to CSV.
execute_query_4: Executes and exports the result of book_purchases_by_team_2023.sql to CSV.

### SQL Scripts

**DDL Scripts**:

create_staging_tables.sql: Creates staging tables.
create_ods_tables.sql: Creates ODS tables.
create_dim_and_fact_tables.sql: Creates dimension and fact tables.
upsert_to_ods.sql: Upserts data to ODS.
truncate_staging_tables.sql: Truncates staging tables.
populate_dim_tables.sql: Populates dimension tables.
populate_fct_tables.sql: Populates fact tables.

**Analytical Queries**:

book_top_3_longest_2022.sql: Analytical query for top 3 longest books in 2022.
lists_least_unique_books.sql: Analytical query for lists with the least unique books.
top_publishers_quarterly_rank.sql: Analytical query for top publishers by quarterly rank.
book_purchases_by_team_2023.sql: Analytical query for book purchases by team in 2023.





   
